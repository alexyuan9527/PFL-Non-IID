==================================================
Algorithm: Ditto
Attackers: 5
Local batch size: 10
Local steps: 1
Local learing rate: 0.005
Local learing rate decay: False
Total number of clients: 10
Clients join in each round: 1.0
Clients randomly join: False
Client drop rate: 0.0
Client select regarding time: False
Running times: 1
Dataset: mnist
Number of classes: 10
Backbone: cnn
Using device: cuda
Using DP: False
Auto break: False
Global rounds: 20
Cuda device id: 0
DLG attack: False
Total number of new clients: 0
Fine tuning epoches on new clients: 0
==================================================

============= Running time: 0th =============
Creating server and clients ...
FedAvgCNN(
  (conv1): Sequential(
    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  )
  (conv2): Sequential(
    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU(inplace=True)
  )
  (fc): Linear(in_features=512, out_features=10, bias=True)
)

Join ratio / total clients: 1.0 / 10
Finished creating server and clients.

-------------Round number: 0-------------

Evaluate global models
Averaged Train Loss: 2.3002
Averaged Test Accurancy: 0.0958    Std Test Accurancy: 0.0651

Evaluate personalized models
Averaged Train Loss: 2.3125
Averaged Test Accurancy: 0.0571    Std Test Accurancy: 0.0535
------------------------- time cost ------------------------- 22.216373205184937

-------------Round number: 1-------------

Evaluate global models
Averaged Train Loss: 2.1703
Averaged Test Accurancy: 0.3894    Std Test Accurancy: 0.3264

Evaluate personalized models
Averaged Train Loss: 5.2675
Averaged Test Accurancy: 0.4674    Std Test Accurancy: 0.4238
------------------------- time cost ------------------------- 20.072296619415283

-------------Round number: 2-------------

Evaluate global models
Averaged Train Loss: 2.1219
Averaged Test Accurancy: 0.5396    Std Test Accurancy: 0.3705

Evaluate personalized models
Averaged Train Loss: 5.2650
Averaged Test Accurancy: 0.4667    Std Test Accurancy: 0.4232
------------------------- time cost ------------------------- 20.082517385482788

-------------Round number: 3-------------

Evaluate global models
Averaged Train Loss: 2.1084
Averaged Test Accurancy: 0.5567    Std Test Accurancy: 0.3801

Evaluate personalized models
Averaged Train Loss: 5.1906
Averaged Test Accurancy: 0.4664    Std Test Accurancy: 0.4264
------------------------- time cost ------------------------- 19.63132381439209

-------------Round number: 4-------------

Evaluate global models
Averaged Train Loss: 2.1002
Averaged Test Accurancy: 0.5559    Std Test Accurancy: 0.3815

Evaluate personalized models
Averaged Train Loss: 5.1349
Averaged Test Accurancy: 0.4673    Std Test Accurancy: 0.4334
------------------------- time cost ------------------------- 20.145848035812378

-------------Round number: 5-------------

Evaluate global models
Averaged Train Loss: 2.0976
Averaged Test Accurancy: 0.5627    Std Test Accurancy: 0.3848

Evaluate personalized models
Averaged Train Loss: 5.1031
Averaged Test Accurancy: 0.4676    Std Test Accurancy: 0.4377
------------------------- time cost ------------------------- 19.69288921356201

-------------Round number: 6-------------

Evaluate global models
Averaged Train Loss: 2.0980
Averaged Test Accurancy: 0.5604    Std Test Accurancy: 0.3833

Evaluate personalized models
Averaged Train Loss: 5.0932
Averaged Test Accurancy: 0.4672    Std Test Accurancy: 0.4392
------------------------- time cost ------------------------- 18.55306601524353

-------------Round number: 7-------------

Evaluate global models
Averaged Train Loss: 2.1006
Averaged Test Accurancy: 0.5620    Std Test Accurancy: 0.3851

Evaluate personalized models
Averaged Train Loss: 5.0920
Averaged Test Accurancy: 0.4670    Std Test Accurancy: 0.4396
------------------------- time cost ------------------------- 19.985984563827515

-------------Round number: 8-------------

Evaluate global models
Averaged Train Loss: 2.0949
Averaged Test Accurancy: 0.5607    Std Test Accurancy: 0.3845

Evaluate personalized models
Averaged Train Loss: 5.0906
Averaged Test Accurancy: 0.4672    Std Test Accurancy: 0.4406
------------------------- time cost ------------------------- 19.086931467056274

-------------Round number: 9-------------

Evaluate global models
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    run(args)
  File "main.py", line 319, in run
    server.train()
  File "E:\Documents\GitHub\PFL-Non-IID\system\flcore\servers\serverditto.py", line 35, in train
    self.evaluate()
  File "E:\Documents\GitHub\PFL-Non-IID\system\flcore\servers\serverbase.py", line 263, in evaluate
    stats_train = self.train_metrics()
  File "E:\Documents\GitHub\PFL-Non-IID\system\flcore\servers\serverbase.py", line 249, in train_metrics
    cl, ns = c.train_metrics()
  File "E:\Documents\GitHub\PFL-Non-IID\system\flcore\clients\clientbase.py", line 145, in train_metrics
    output = self.model(x)
  File "D:\Software\Anaconda\envs\pfl\lib\site-packages\torch\nn\modules\module.py", line 1189, in _call_impl
    forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
KeyboardInterrupt
